{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 20)\n",
      "[ 5  6 12 26 27 28 21 29 24 25]\n"
     ]
    }
   ],
   "source": [
    "decorrelated_tx, deleted_features = decorrelate_features(tX)\n",
    "print(decorrelated_tx.shape)\n",
    "print(deleted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68114, 20)\n"
     ]
    }
   ],
   "source": [
    "usable_tx, usable_indices = delete_outliers(decorrelated_tx, -990)\n",
    "usable_tx = usable_tx[0]\n",
    "print(usable_tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68114, 60)\n",
      "[138.47   89.744 148.754 114.744 141.481]\n",
      "[19173.9409    8053.985536 22127.752516 13166.185536 20016.873361]\n"
     ]
    }
   ],
   "source": [
    "augmented_features = polynomial_embedding(usable_tx)\n",
    "print(augmented_features.shape)\n",
    "print(augmented_features[0:5, 0])\n",
    "print(augmented_features[0:5, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_tX = add_offset(usable_tx)\n",
    "w_init_offset = 1e-2*np.ones((offset_tX.shape[1],))\n",
    "usable_y = y[usable_indices]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# TOY MODEL :\n",
    "\n",
    "toy_X = np.random.rand(100, 2)\n",
    "toy_offset_X = add_offset(toy_X)\n",
    "\n",
    "toy_y = 2*toy_offset_X[:, 0] + toy_offset_X[:, 1] + 3*toy_offset_X[:, 2]   # y = 2 + X1 + 3*X2\n",
    "\n",
    "#w_init_offset = 1e-2*np.ones((offset_X.shape[1],))\n",
    "w_init_toy = np.array([1, 1, 3])\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "test_tX = offset_tX[:, :2]\n",
    "w_init_test = 1e-2*np.ones((test_tX.shape[1],))\n",
    "\n",
    "w_init = 1e-2*np.ones((tX.shape[1],))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final, losses = SGD(usable_y, offset_tX, w_init_offset, 1e-3, 100, print_stuff=10, batch_size = 100, return_losses=True)\n",
    "#w_final, losses = SGD(toy_y, toy_offset_X, w_init_toy, 2e-2, 1000, print_stuff=50, batch_size = 100, return_losses=True)\n",
    "#w, loss = SGD(y, offset_tX, w_init_offset, 100, 1e-2, 128)\n",
    "#w, loss = least_squares_GD(y, offset_tX, w_init_offset, 100, 1e-3)\n",
    "#print(w_final)\n",
    "#plt.plot(np.linspace(0, 1000, 1000), losses, 'b')\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
