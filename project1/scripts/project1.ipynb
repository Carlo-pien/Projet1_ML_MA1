{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -2.475 -999.    -999.    -999.    -999.       3.106   -2.767 -999.\n",
      " -999.    -999.   ]\n"
     ]
    }
   ],
   "source": [
    "print(tX[0:10, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26123, 19)\n",
      "(7562, 21)\n",
      "(4429, 29)\n",
      "(73790, 20)\n",
      "(69982, 22)\n",
      "(68114, 30)\n",
      "[[ 86.24   79.692  27.201 ... 250.178   0.      0.   ]\n",
      " [109.412  14.398  17.323 ... 198.616   0.      0.   ]\n",
      " [ 85.186  68.827   5.042 ... 151.816   0.      0.   ]\n",
      " ...\n",
      " [ 71.989  36.548   5.042 ... 144.665   0.      0.   ]\n",
      " [ 58.179  68.083  22.439 ...  80.408   0.      0.   ]\n",
      " [ 72.756  70.831   7.479 ...  99.405   0.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "data, ids = divide_in_groups(tX)\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)\n",
    "print(data[2].shape)\n",
    "print(data[3].shape)\n",
    "print(data[4].shape)\n",
    "print(data[5].shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 10)\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64),)\n",
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "PCX, P, ids = PCA(tX, threshold=.9)\n",
    "print(PCX.shape)\n",
    "print(ids)\n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "nonzero_var_tx = delete_zero_var_features(tX)\n",
    "print(nonzero_var_tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 20)\n",
      "[ 5  6 12 26 27 28 21 29 24 25]\n"
     ]
    }
   ],
   "source": [
    "decorrelated_tx, deleted_features = decorrelate_features(nonzero_var_tx)\n",
    "print(decorrelated_tx.shape)\n",
    "print(deleted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68114, 20)\n"
     ]
    }
   ],
   "source": [
    "usable_tx, usable_indices = delete_outliers(decorrelated_tx, -990)\n",
    "usable_tx = usable_tx[0]\n",
    "print(usable_tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68114, 40)\n"
     ]
    }
   ],
   "source": [
    "augmented_features = polynomial_embedding(usable_tx)\n",
    "print(augmented_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_tX = add_offset(usable_tx)\n",
    "w_init_offset = 1e-2*np.ones((offset_tX.shape[1],))\n",
    "usable_y = y[usable_indices] \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# TOY MODEL :\n",
    "\n",
    "toy_X = np.random.rand(100, 2)\n",
    "toy_offset_X = add_offset(toy_X)\n",
    "\n",
    "toy_y = 2*toy_offset_X[:, 0] + toy_offset_X[:, 1] + 3*toy_offset_X[:, 2]   # y = 2 + X1 + 3*X2\n",
    "\n",
    "#w_init_offset = 1e-2*np.ones((offset_X.shape[1],))\n",
    "w_init_toy = np.array([1, 1, 3])\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "test_tX = offset_tX[:, :2]\n",
    "w_init_test = 1e-2*np.ones((test_tX.shape[1],))\n",
    "\n",
    "w_init = 1e-2*np.ones((tX.shape[1],))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final, losses = SGD(usable_y, offset_tX, w_init_offset, 1e-3, 100, print_stuff=10, batch_size = 100, return_losses=True)\n",
    "#w_final, losses = SGD(toy_y, toy_offset_X, w_init_toy, 2e-2, 1000, print_stuff=50, batch_size = 100, return_losses=True)\n",
    "#w, loss = SGD(y, offset_tX, w_init_offset, 100, 1e-2, 128)\n",
    "#w, loss = least_squares_GD(y, offset_tX, w_init_offset, 100, 1e-3)\n",
    "#print(w_final)\n",
    "#plt.plot(np.linspace(0, 1000, 1000), losses, 'b')\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 5 6]\n",
      " [3 8 9]]\n",
      "[0.66666667 6.         6.        ]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [2, 5, 6], [3, 8, 9]])\n",
    "print(A)\n",
    "print(np.var(A, axis=0))\n",
    "\n",
    "#B = np.array([1, 2, 3, 4])\n",
    "#print(B[np.where(B<4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
